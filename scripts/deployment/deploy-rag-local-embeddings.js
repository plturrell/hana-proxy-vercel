import { createClient } from '@supabase/supabase-js';
import { promises as fs } from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Initialize Supabase client
const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY // Use service role key for admin operations
);

async function deployRAGWithLocalEmbeddings() {
  console.log('üöÄ Deploying RAG System with Local Hugging Face Embeddings...');

  try {
    // 1. Read and execute the database schema
    console.log('üìä Setting up database schema...');
    const sqlPath = path.join(__dirname, 'deploy-rag-complete.sql');
    const sql = await fs.readFile(sqlPath, 'utf8');
    
    // Split SQL into individual statements
    const statements = sql
      .split(';')
      .map(s => s.trim())
      .filter(s => s && !s.startsWith('--'));

    for (const statement of statements) {
      if (statement) {
        try {
          const { error } = await supabase.rpc('exec_sql', { sql: statement });
          if (error) {
            console.warn(`Warning: ${error.message}`);
          }
        } catch (err) {
          console.warn(`Warning: ${err.message}`);
        }
      }
    }

    // 2. Verify tables exist
    console.log('üîç Verifying database tables...');
    const { data: tables, error: tablesError } = await supabase
      .from('information_schema.tables')
      .select('table_name')
      .eq('table_schema', 'public')
      .in('table_name', ['documents', 'document_chunks', 'document_processing_status', 'search_history']);

    if (tablesError) {
      console.error('Error checking tables:', tablesError);
    } else {
      console.log('‚úÖ Tables verified:', tables.map(t => t.table_name));
    }

    // 3. Test local embedding pipeline
    console.log('ü§ñ Testing local embedding model...');
    try {
      const testResponse = await fetch('http://localhost:3000/api/rag/query-embedding', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ query: 'test query for financial analysis' })
      });

      if (testResponse.ok) {
        const testData = await testResponse.json();
        console.log(`‚úÖ Local embeddings working: ${testData.model} (${testData.dimensions.original}‚Üí${testData.dimensions.padded} dims)`);
      } else {
        console.warn('‚ö†Ô∏è Local embeddings endpoint not responding (will work after deployment)');
      }
    } catch (err) {
      console.warn('‚ö†Ô∏è Local embeddings test failed (expected during deployment)');
    }

    // 4. Insert test documents
    console.log('üìÑ Creating test documents...');
    const testDocs = [
      {
        title: 'Financial Analysis Guide',
        file_type: 'text/markdown',
        file_size_bytes: 2048,
        metadata: { category: 'education', topic: 'finance' }
      },
      {
        title: 'Risk Management Principles',
        file_type: 'text/plain',
        file_size_bytes: 1536,
        metadata: { category: 'guide', topic: 'risk' }
      }
    ];

    for (const doc of testDocs) {
      const { data, error } = await supabase
        .from('documents')
        .insert(doc)
        .select()
        .single();

      if (error) {
        console.warn(`Warning creating document "${doc.title}":`, error.message);
      } else {
        console.log(`‚úÖ Created document: ${data.title} (ID: ${data.id})`);
        
        // Add test chunks
        const chunks = [
          {
            document_id: data.id,
            chunk_index: 0,
            content: `This is test content for ${doc.title}. It covers key concepts in financial analysis and provides practical guidance for implementation.`,
            token_count: 25,
            metadata: { section: 'introduction', test: true }
          }
        ];

        const { error: chunkError } = await supabase
          .from('document_chunks')
          .insert(chunks);

        if (chunkError) {
          console.warn('Warning creating chunks:', chunkError.message);
        } else {
          console.log(`‚úÖ Added ${chunks.length} chunks to "${data.title}"`);
        }
      }
    }

    // 5. Test Grok-4 integration
    console.log('üß† Testing Grok-4 integration...');
    const grokApiKey = process.env.GROK4_API_KEY || process.env.XAI_API_KEY;
    if (grokApiKey) {
      console.log('‚úÖ Grok-4 API key configured');
    } else {
      console.warn('‚ö†Ô∏è Grok-4 API key not configured - set GROK4_API_KEY or XAI_API_KEY');
    }

    // 6. Generate deployment summary
    const { data: docCount } = await supabase
      .from('documents')
      .select('id', { count: 'exact' });

    const { data: chunkCount } = await supabase
      .from('document_chunks')
      .select('id', { count: 'exact' });

    console.log('\nüéâ RAG System Deployment Complete!');
    console.log('=' .repeat(50));
    console.log(`üìä Documents: ${docCount?.length || 0}`);
    console.log(`üìù Chunks: ${chunkCount?.length || 0}`);
    console.log(`ü§ñ Embedding Model: all-MiniLM-L6-v2 (local)`);
    console.log(`üß† AI Model: Grok-4`);
    console.log(`üíæ Database: Supabase with pgvector`);
    console.log('=' .repeat(50));
    console.log('\nüöÄ Ready for production use!');
    console.log('- Upload documents via /api/rag/process');
    console.log('- Search documents via /api/rag/search');
    console.log('- Access via teach-jobs.html knowledge base');

  } catch (error) {
    console.error('‚ùå Deployment failed:', error);
    process.exit(1);
  }
}

// Run deployment
if (import.meta.url === `file://${process.argv[1]}`) {
  deployRAGWithLocalEmbeddings();
}

export default deployRAGWithLocalEmbeddings;